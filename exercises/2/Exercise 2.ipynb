{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Each exercise (except for the first) corresponds to one python file. The results can be replicated by running these code files directly (setup and configuration is done in the `main` section at the bottom of the files) or the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bayes' Theorem\n",
    "\n",
    "Note: We assume that $0.5%$ of the population are drug users, not $0.05%$ - otherwise the percentages of drug users and non-users don't add up to 100.\n",
    "No code is provided for this example, results were computed manually.\n",
    "\n",
    "$P(A|B) = P(B|A)P(A) / P(B)$\n",
    "\n",
    "Here: \n",
    "* $P(A|B)$ -> Probability of observing that a randomly selected individual is not a drug user given a positive drug test. $P(A|B)$ = ?\n",
    "* $A$ -> Not a drug user. $P(A) = 0.995$, $P(¬A) = 1 - P(A) = 0.005$.\n",
    "* $B$ -> Positive drug test. $P(B) = P(A) * 0.01 + P(¬A) * 0.99 = 0.995 * 0.01 + 0.005 * 0.99 = 0.00995 + 0.00495 = 0.0149$.\n",
    "* $P(B|A)$ -> Probability of observing a positive drug test given a non-user. $P(B|A) = 0.01$.\n",
    "\n",
    "Hence:\n",
    "$P(A|B) = 0.01 * 0.995 / 0.0149 = 0.6677852349 ~ 66.7%$\n",
    "\n",
    "**Interpretation**: Due to the group of non-users being the vast majority, the test (with a sensitivity of 99%) generates more false positives than true positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A-B Testing\n",
    "\n",
    "Code can be found in `a_b_testing.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency, binom_test\n",
    "from scipy.special import ndtr\n",
    "import numpy as np\n",
    "\n",
    "# Data pre-processing.\n",
    "df = pd.read_csv(\"ab_data.csv\")\n",
    "num_new_page = len(df[df.landing_page == \"new_page\"])\n",
    "num_old_page = len(df[df.landing_page == \"old_page\"])\n",
    "num_conversions = len(df[df.converted == 1])\n",
    "num_conversions_old = len(df[(df.landing_page == \"old_page\") & (df.converted == 1)])\n",
    "num_conversions_new = len(df[(df.landing_page == \"new_page\") & (df.converted == 1)])\n",
    "contingency_table = pd.crosstab(df.landing_page, df.converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traffic Split and Conversion Rate\n",
    "*(a) In what proportion did the company split the landing page?*  \n",
    "40000:60000 = 40.0% of all visits were redirected to the new page.   \n",
    "\n",
    "*(b) What is the conversion rate for each version of the landing page?*  \n",
    "* Old page: $0.12063333333333333$. \n",
    "* New page: $0.1191$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1a. In what proportion did the company split the landing page?\n",
      " 40000:60000 = 40.0% of all visits were redirected to the new page. \n",
      "2.1b. What is the conversion rate for each version of the landing page?\n",
      "  Old page: 0.12063333333333333. \n",
      "  New page: 0.1191.\n"
     ]
    }
   ],
   "source": [
    "    # 2.1a. In what proportion did the company split the landing page?\n",
    "    print(\n",
    "        \"2.1a. In what proportion did the company split the landing page?\\n\",\n",
    "        str(num_new_page) + \":\" + str(num_old_page),\n",
    "        \"= \" + str(num_new_page / len(df) * 100) + \"% of all visits were redirected to the new page. \"\n",
    "    )\n",
    "\n",
    "    # 2.1b. What is the conversion rate for each version of the landing page?\n",
    "    print(\n",
    "        \"2.1b. What is the conversion rate for each version of the landing page?\\n\",\n",
    "        \" Old page: \" + str(num_conversions_old / num_old_page) + \".\",\n",
    "        \"\\n  New page: \" + str(num_conversions_new / num_new_page) + \".\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Test \n",
    "\n",
    "We phrase $H_0$ as follows: The probability of observing the specified number of conversions with the specified landing page version is not higher than 50%. This is a rephrased variant of the original hypothesis of \"the probability of conversion does not depend on the landing page\". We used $p = 0.5$ to reflect the equaliy assumption in $H_0$.\n",
    "\n",
    "Probability of observing observed number of conversations given the assumptions above and using scipy's binomial test:\n",
    "* Old page: $p = 6.317471224286417e-114$. \n",
    "* New page: $p = 0.9999999999999999$.\n",
    "\n",
    "Assuming a significance level of $0.05$, we can interpret this result as follows: \n",
    "* The probability for the old landing page is lower than our alpha. This means we can reject $H_0$ - \n",
    "that the old landing page's chance of success is not higher than 50% when compare with the new landing page.\n",
    "* The probability for the new landin page is higher than our alpha. This means we cannot reject $H_0$ and the new landing page's chance of success compared to the old version is indeed not higher than 50%.\n",
    "\n",
    "Intuitively speaking, this makes sense - the number of conversions stemming from the old landing page are considerably \n",
    "higher than the one from the new one and we have thousands of samples, so we would expect the old landing page having a \n",
    "more than even chance of success when compared to the new version.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.2. Probability of observing observed number of conversations if probability of conversation does not depend on landing page version.\n",
      "  Old page: 6.317471224286417e-114. \n",
      "  New page: 0.9999999999999999.\n"
     ]
    }
   ],
   "source": [
    "# 2.2. Under the hypothesis that the probability of conversion does not depend on the version of the landing page\n",
    "# with the help of a binomial-test find how likely it is to observe the number of conversions as extreme as the one\n",
    "# for the old landing page and the one for the new landing page.\n",
    "print(\n",
    "    \"\\n2.2. Probability of observing observed number of conversations if probability of conversation does not \"\n",
    "    \"depend on landing page version.\\n\",\n",
    "    \" Old page: \" + str(binom_test(num_conversions_old, n=num_conversions, p=0.5, alternative='greater')) + \".\",\n",
    "    \"\\n  New page: \" + str(binom_test(num_conversions_new, n=num_conversions, p=0.5, alternative='greater')) + \".\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared and Normal Test\n",
    "\n",
    "We assume $H_0$ to state that there is no significant difference in conversion rates between landing page versions.\n",
    "\n",
    "Significances in differences in conversion rates w.r.t. landing page versions.\n",
    "* χ2: $p = 0.4709069331806466$.\n",
    "* normality test: $p = 0.6616312516159468$.\n",
    "\n",
    "The χ2 result was computed by aggregating the available data to a contingency table before using scipy's \n",
    "`chi2_contingency`. The normal test was computed manually by following the equation in the slides - computing \n",
    "$t_a, t_b, z$ as consequence of the number of successes and the numbers of tries and then retrieving the p-value via the computed z-score.\n",
    "\n",
    "We can interpret both (χ2 and normal test) results the same way: We can hence reject $H_0$, i. e. the claim that there is significant differences in conversion rates between landing pages is false.\n",
    "This conclusion is in agreement with both the result from the binomial tests and our intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.3. Significances in differences in conversion rates w.r.t. landing page versions.\n",
      " χ2: p = 0.4709069331806466\n",
      " normality test: p = 0.6616312516159468\n"
     ]
    }
   ],
   "source": [
    "# 2.3. Under the same null hypothesis use the χ-squared test and the normal-test to measure the significance of the\n",
    "# difference in the conversion-rates of the landing page versions. Same H_0 as in 2.2.\n",
    "\n",
    "t_a = num_conversions_old / num_old_page\n",
    "t_b = num_conversions_new / num_new_page\n",
    "z = (t_a - t_b) / np.sqrt(\n",
    "    np.std(df[df.landing_page == \"old_page\"].converted) / num_old_page +\n",
    "    np.std(df[df.landing_page == \"new_page\"].converted) / num_new_page\n",
    ")\n",
    "\n",
    "stat, p_chi2, dof, expected = chi2_contingency(contingency_table.values)\n",
    "print(\n",
    "    \"\\n2.3. Significances in differences in conversion rates w.r.t. landing page versions.\\n\",\n",
    "    \"χ2: p = \" + str(p_chi2) +\n",
    "    \"\\n normality test: p = \" + str(ndtr(z))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression\n",
    "\n",
    "Code can be found in `logistic_regression.py`.\n",
    "\n",
    "We compared our implementation with sklearn's `sklearn.linear_model.LogisticRegression` and mimicked parts of its interfaces. While our model takes considerably longer to converge, it approximates sklearn's accuracy closely when the right learning rate is chosen. We choose the F1 score to reflect the quality of the prediction for our evaluation. Our implementation stops whenver the maximum number of iterations is reached or the result of the loss function converges to a value that is lower than the specified threshold. We used a train-test split with a proportion of $\\frac{2}{3}$ : $\\frac{1}{3}$.\n",
    "\n",
    "Utilizing a grid search, the best learning rate seems to be 0.001. In the following a list of tried learning rate values \n",
    "together with the computed F1-score:\n",
    "```\n",
    "  0.05:    0.6011731155616048\n",
    "  0.01:    0.5804276660764605\n",
    "  0.005:   0.6407631173854077\n",
    "  0.001:   0.7605988196913313\n",
    "  0.0005:  0.7558456670258468\n",
    "  0.0001:  0.7300973641595375\n",
    "  sklearn: 0.7616874084952325\n",
    "```\n",
    "As can be seen here, sklearn's implementation beats our vanilla implementation (using a learning rate of $0.001$) by a tiny fraction, but the difference is marginal. Note that we didn't optimize the hyperparameters for sklearn's LR however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[744 855]\n",
      "*** Evalution + hyperparameter search ***\n",
      "  In split 1\n",
      "    learning rate = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raphael/Development/univie-business-intelligence/exercises/2/logistic_regression.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
      "/home/raphael/Development/univie-business-intelligence/exercises/2/logistic_regression.py:70: RuntimeWarning: invalid value encountered in multiply\n",
      "  cost = (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    learning rate = 0.01\n",
      "    learning rate = 0.005\n",
      "    learning rate = 0.001\n",
      "    learning rate = 0.0005\n",
      "    learning rate = 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raphael/.conda/envs/univie-busint/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/raphael/Development/univie-business-intelligence/exercises/2/logistic_regression.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
      "/home/raphael/Development/univie-business-intelligence/exercises/2/logistic_regression.py:70: RuntimeWarning: invalid value encountered in multiply\n",
      "  cost = (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  In split 2\n",
      "    learning rate = 0.05\n",
      "    learning rate = 0.01\n",
      "    learning rate = 0.005\n",
      "    learning rate = 0.001\n",
      "    learning rate = 0.0005\n",
      "    learning rate = 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raphael/.conda/envs/univie-busint/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/raphael/Development/univie-business-intelligence/exercises/2/logistic_regression.py:70: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
      "/home/raphael/Development/univie-business-intelligence/exercises/2/logistic_regression.py:70: RuntimeWarning: invalid value encountered in multiply\n",
      "  cost = (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  In split 3\n",
      "    learning rate = 0.05\n",
      "    learning rate = 0.01\n",
      "    learning rate = 0.005\n",
      "    learning rate = 0.001\n",
      "    learning rate = 0.0005\n",
      "    learning rate = 0.0001\n",
      "\n",
      "  0.05: 0.6011731155616048\n",
      "  0.01: 0.5804276660764605\n",
      "  0.005: 0.6407631173854077\n",
      "  0.001: 0.7605988196913313\n",
      "  0.0005: 0.7558456670258468\n",
      "  0.0001: 0.7300973641595375\n",
      "  sklearn: 0.7616874084952325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raphael/.conda/envs/univie-busint/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression as SKLearnLogisticRegression\n",
    "from typing import Tuple\n",
    "from logistic_regression import LogisticRegression, evaluate\n",
    "\n",
    "\n",
    "wine_df = pd.read_csv(\"winequality_binary.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "features = wine_df.drop(columns=[\"quality\"])\n",
    "labels = wine_df[[\"quality\"]]\n",
    "\n",
    "# Check distribution of class labels.\n",
    "unique, counts = np.unique(labels.values, return_counts=True)\n",
    "print(counts)\n",
    "\n",
    "#############################################################\n",
    "# 3. Logistic regression.\n",
    "#############################################################\n",
    "\n",
    "print(\"*** Evalution + hyperparameter search ***\")\n",
    "\n",
    "# Search for best parameter for learning rate, compare with sklearn implementation.\n",
    "learning_rates = (5e-2, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4)\n",
    "n_splits = 3\n",
    "f1_scores = {lr: 0 for lr in learning_rates}\n",
    "f1_scores[\"sklearn\"] = 0\n",
    "\n",
    "for j in range(n_splits):\n",
    "    print(\"  In split\", j + 1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features.values, labels.values, test_size=0.33)\n",
    "\n",
    "    # Evaluate own implementation with different parametrizations.\n",
    "    for learning_rate in learning_rates:\n",
    "        print(\"    learning rate =\", learning_rate)\n",
    "        tp, fp, tn, fn = evaluate(X_train, y_train, X_test, y_test, learning_rate=learning_rate)\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1_scores[learning_rate] += 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    # Evaluate with sklearn.\n",
    "    tp, fp, tn, fn = evaluate(X_train, y_train, X_test, y_test, use_own=False)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_scores[\"sklearn\"] += 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print()\n",
    "for config in f1_scores:\n",
    "    f1_scores[config] /= n_splits\n",
    "    print(\"  \" + str(config) + \": \" + str(f1_scores[config]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Confidence Interval of the Prediction Accuracy\n",
    "\n",
    "We assumed a confidence level of $0.95$ and ran all tests with our vanilla implementatin of logistic regresion and the \n",
    "optimal learning rate found in the previous task. We implemented pseudocode for bootstrapping we found online and the\n",
    "same evaluation methds as for the previous task to gather a accuracy statistic. Following that, we pick the alpha-/\n",
    "confidence level-percentiles from this statistic.\n",
    "\n",
    "We used a train-test split with a proportion of $\\frac{1}{2}$:$\\frac{1}{2}$, following sklearn's default values. We ran 50 iterations. \n",
    "Predicting the results with these pre-conditions yields a $0.95$-confidence of $(69.42187499999999, 75.27604166666666)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Bootstrapping ***\n",
      "  Iteration #0\n",
      "0.7229166666666667\n",
      "  Iteration #1\n",
      "0.7208333333333333\n",
      "  Iteration #2\n",
      "0.73125\n",
      "  Iteration #3\n",
      "0.7145833333333333\n",
      "  Iteration #4\n",
      "0.7166666666666667\n",
      "  Iteration #5\n",
      "0.7166666666666667\n",
      "  Iteration #6\n",
      "0.7166666666666667\n",
      "  Iteration #7\n",
      "0.7333333333333333\n",
      "  Iteration #8\n",
      "0.71875\n",
      "  Iteration #9\n",
      "0.7270833333333333\n",
      "  Iteration #10\n",
      "0.7020833333333333\n",
      "  Iteration #11\n",
      "0.71875\n",
      "  Iteration #12\n",
      "0.7375\n",
      "  Iteration #13\n",
      "0.7041666666666667\n",
      "  Iteration #14\n",
      "0.7208333333333333\n",
      "  Iteration #15\n",
      "0.7375\n",
      "  Iteration #16\n",
      "0.6958333333333333\n",
      "  Iteration #17\n",
      "0.7333333333333333\n",
      "  Iteration #18\n",
      "0.725\n",
      "  Iteration #19\n",
      "0.69375\n",
      "  Iteration #20\n",
      "0.7125\n",
      "  Iteration #21\n",
      "0.7354166666666667\n",
      "  Iteration #22\n",
      "0.6895833333333333\n",
      "  Iteration #23\n",
      "0.70625\n",
      "  Iteration #24\n",
      "0.7291666666666666\n",
      "  Iteration #25\n",
      "0.7020833333333333\n",
      "  Iteration #26\n",
      "0.7229166666666667\n",
      "  Iteration #27\n",
      "0.73125\n",
      "  Iteration #28\n",
      "0.7145833333333333\n",
      "  Iteration #29\n",
      "0.73125\n",
      "  Iteration #30\n",
      "0.7166666666666667\n",
      "  Iteration #31\n",
      "0.7416666666666667\n",
      "  Iteration #32\n",
      "0.74375\n",
      "  Iteration #33\n",
      "0.7125\n",
      "  Iteration #34\n",
      "0.73125\n",
      "  Iteration #35\n",
      "0.7208333333333333\n",
      "  Iteration #36\n",
      "0.7041666666666667\n",
      "  Iteration #37\n",
      "0.6979166666666666\n",
      "  Iteration #38\n",
      "0.7375\n",
      "  Iteration #39\n",
      "0.7541666666666667\n",
      "  Iteration #40\n",
      "0.7333333333333333\n",
      "  Iteration #41\n",
      "0.7375\n",
      "  Iteration #42\n",
      "0.7416666666666667\n",
      "  Iteration #43\n",
      "0.7333333333333333\n",
      "  Iteration #44\n",
      "0.7479166666666667\n",
      "  Iteration #45\n",
      "0.76875\n",
      "  Iteration #46\n",
      "0.74375\n",
      "  Iteration #47\n",
      "0.7333333333333333\n",
      "  Iteration #48\n",
      "0.7291666666666666\n",
      "  Iteration #49\n",
      "0.7291666666666666\n",
      "(69.42187499999999, 75.27604166666666)\n"
     ]
    }
   ],
   "source": [
    "from bootstrapping import compute_bootstrap_accuracy\n",
    "\n",
    "wine_df = pd.read_csv(\"winequality_binary.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "features = wine_df.drop(columns=[\"quality\"])\n",
    "labels = wine_df[[\"quality\"]]\n",
    "\n",
    "#############################################################\n",
    "# Confidence interval of prediction accuracy.\n",
    "#############################################################\n",
    "\n",
    "print(\"*** Bootstrapping ***\")\n",
    "print(compute_bootstrap_accuracy(features.values, labels.values, n_bootstraps=50, n_train=0.7))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "univie-busint",
   "language": "python",
   "name": "univie-busint"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
